{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3019b7c4-52f8-4b90-bc55-ffd149d4fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.45.1)\n",
      "Requirement already satisfied: ninja in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.11.1.4)\n",
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.5.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.31.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.5.1\n",
      "    Uninstalling datasets-3.5.1:\n",
      "      Successfully uninstalled datasets-3.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "axolotl 0.9.2 requires datasets==3.5.1, but you have datasets 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U wheel ninja datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a732ba-6f8c-40ac-b347-fc123c965396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cu124\n",
      "Uninstalling torch-2.6.0+cu124:\n",
      "  Successfully uninstalled torch-2.6.0+cu124\n",
      "Found existing installation: torchaudio 2.6.0+cu124\n",
      "Uninstalling torchaudio-2.6.0+cu124:\n",
      "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
      "Found existing installation: torchvision 0.21.0+cu124\n",
      "Uninstalling torchvision-0.21.0+cu124:\n",
      "  Successfully uninstalled torchvision-0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall --yes torch torchaudio torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e07f861-9a39-4b34-b805-6927309244f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.6.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.21.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio==2.6.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (4.14.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision==0.21.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision==0.21.0) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl (768.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [torchaudio]3\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "axolotl 0.9.2 requires datasets==3.5.1, but you have datasets 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4217aba3-4433-4f02-b29f-dc8bc56f2ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: axolotl[deepspeed,flash-attn] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.9.2)\n",
      "Requirement already satisfied: bitsandbytes==0.45.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.45.4)\n",
      "Requirement already satisfied: triton>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (3.2.0)\n",
      "Requirement already satisfied: autoawq==0.2.7.post3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.2.7.post3)\n",
      "Requirement already satisfied: liger-kernel==0.5.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.5.9)\n",
      "Requirement already satisfied: packaging==23.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (23.2)\n",
      "Requirement already satisfied: huggingface_hub==0.31.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.31.0)\n",
      "Requirement already satisfied: peft==0.15.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.15.2)\n",
      "Requirement already satisfied: transformers==4.51.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (4.51.3)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.21.1)\n",
      "Requirement already satisfied: accelerate==1.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.6.0)\n",
      "Collecting datasets==3.5.1 (from axolotl[deepspeed,flash-attn])\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: trl==0.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.17.0)\n",
      "Requirement already satisfied: hf_xet==1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.1.0)\n",
      "Requirement already satisfied: hqq==0.2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.2.5)\n",
      "Requirement already satisfied: optimum==1.16.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.16.2)\n",
      "Requirement already satisfied: hf_transfer in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.1.9)\n",
      "Requirement already satisfied: sentencepiece in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.2.0)\n",
      "Requirement already satisfied: gradio==5.23.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (5.23.3)\n",
      "Requirement already satisfied: modal==0.70.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.70.5)\n",
      "Requirement already satisfied: pydantic==2.10.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2.10.6)\n",
      "Requirement already satisfied: addict in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2.4.0)\n",
      "Requirement already satisfied: fire in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (6.0.2)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2.32.3)\n",
      "Requirement already satisfied: wandb in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.20.1)\n",
      "Requirement already satisfied: einops in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.8.1)\n",
      "Requirement already satisfied: colorama in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.4.6)\n",
      "Requirement already satisfied: numba in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.61.2)\n",
      "Requirement already satisfied: numpy<=2.0.1,>=1.24.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.26.4)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.4.1)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn==1.4.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.4.2)\n",
      "Requirement already satisfied: nvidia-ml-py==12.560.30 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (12.560.30)\n",
      "Requirement already satisfied: art in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (6.5)\n",
      "Requirement already satisfied: tensorboard in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2.15.1)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.0.1)\n",
      "Requirement already satisfied: s3fs>=2024.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2025.3.0)\n",
      "Requirement already satisfied: gcsfs>=2024.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2025.3.0)\n",
      "Requirement already satisfied: adlfs>=2024.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2024.12.0)\n",
      "Requirement already satisfied: ocifs==1.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.3.2)\n",
      "Requirement already satisfied: zstandard==0.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.22.0)\n",
      "Requirement already satisfied: fastcore in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.8.2)\n",
      "Requirement already satisfied: lm_eval==0.4.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.4.7)\n",
      "Requirement already satisfied: langdetect==1.0.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.0.9)\n",
      "Requirement already satisfied: immutabledict==4.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (4.2.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.13.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (4.13.2)\n",
      "Requirement already satisfied: torchao==0.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.9.0)\n",
      "Requirement already satisfied: schedulefree==1.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (1.4.1)\n",
      "Requirement already satisfied: axolotl-contribs-lgpl==0.0.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.0.6)\n",
      "Requirement already satisfied: axolotl-contribs-mit==0.0.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.0.3)\n",
      "Requirement already satisfied: torch==2.6.0+cu124 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2.6.0+cu124)\n",
      "Requirement already satisfied: xformers==0.0.29.post2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.0.29.post2)\n",
      "Requirement already satisfied: flash-attn==2.7.4.post1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (2.7.4.post1)\n",
      "Requirement already satisfied: deepspeed==0.15.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.15.4)\n",
      "Requirement already satisfied: deepspeed-kernels in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from axolotl[deepspeed,flash-attn]) (0.0.1.dev1698255861)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.6.0->axolotl[deepspeed,flash-attn]) (7.0.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.6.0->axolotl[deepspeed,flash-attn]) (0.5.3)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from autoawq==0.2.7.post3->axolotl[deepspeed,flash-attn]) (4.14.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (3.18.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (1.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.5.1->axolotl[deepspeed,flash-attn]) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.5.1->axolotl[deepspeed,flash-attn]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.5.1->axolotl[deepspeed,flash-attn]) (2.1.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.5.1->axolotl[deepspeed,flash-attn]) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.5.1->axolotl[deepspeed,flash-attn]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.5.1->axolotl[deepspeed,flash-attn]) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.5.1->axolotl[deepspeed,flash-attn]) (3.12.9)\n",
      "Requirement already satisfied: hjson in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from deepspeed==0.15.4->axolotl[deepspeed,flash-attn]) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from deepspeed==0.15.4->axolotl[deepspeed,flash-attn]) (1.1.1)\n",
      "Requirement already satisfied: ninja in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from deepspeed==0.15.4->axolotl[deepspeed,flash-attn]) (1.11.1.4)\n",
      "Requirement already satisfied: py-cpuinfo in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from deepspeed==0.15.4->axolotl[deepspeed,flash-attn]) (9.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate==0.4.1->axolotl[deepspeed,flash-attn]) (0.18.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (3.10.18)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (11.2.1)\n",
      "Requirement already satisfied: pydub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.11.13)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.16.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.34.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic==2.10.6->axolotl[deepspeed,flash-attn]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic==2.10.6->axolotl[deepspeed,flash-attn]) (2.27.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio-client==1.8.0->gradio==5.23.3->axolotl[deepspeed,flash-attn]) (15.0.1)\n",
      "Requirement already satisfied: termcolor in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from hqq==0.2.5->axolotl[deepspeed,flash-attn]) (3.1.0)\n",
      "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from langdetect==1.0.9->axolotl[deepspeed,flash-attn]) (1.17.0)\n",
      "Requirement already satisfied: jsonlines in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (2.11.0)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (2.13.6)\n",
      "Requirement already satisfied: pytablewriter in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (2.5.1)\n",
      "Requirement already satisfied: sqlitedict in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (2.1.0)\n",
      "Requirement already satisfied: tqdm-multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (0.0.11)\n",
      "Requirement already satisfied: word2number in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (1.1)\n",
      "Requirement already satisfied: more_itertools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (10.7.0)\n",
      "Requirement already satisfied: certifi in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (2025.4.26)\n",
      "Requirement already satisfied: click>=8.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (8.2.1)\n",
      "Requirement already satisfied: grpclib==0.4.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (0.4.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<6.0,>=3.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (4.23.4)\n",
      "Requirement already satisfied: rich>=12.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (14.0.0)\n",
      "Requirement already satisfied: synchronicity~=0.9.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (0.9.15)\n",
      "Requirement already satisfied: toml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (0.10.2)\n",
      "Requirement already satisfied: types-certifi in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (2021.10.8.3)\n",
      "Requirement already satisfied: types-toml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (0.10.8.20240310)\n",
      "Requirement already satisfied: watchfiles in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modal==0.70.5->axolotl[deepspeed,flash-attn]) (1.0.5)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from grpclib==0.4.7->modal==0.70.5->axolotl[deepspeed,flash-attn]) (4.2.0)\n",
      "Requirement already satisfied: multidict in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from grpclib==0.4.7->modal==0.70.5->axolotl[deepspeed,flash-attn]) (6.4.4)\n",
      "Requirement already satisfied: oci>=2.43.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ocifs==1.3.2->axolotl[deepspeed,flash-attn]) (2.154.1)\n",
      "Requirement already satisfied: coloredlogs in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optimum==1.16.2->axolotl[deepspeed,flash-attn]) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn==1.4.2->axolotl[deepspeed,flash-attn]) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn==1.4.2->axolotl[deepspeed,flash-attn]) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.6.0+cu124->axolotl[deepspeed,flash-attn]) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.51.3->axolotl[deepspeed,flash-attn]) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.23.3->axolotl[deepspeed,flash-attn]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.23.3->axolotl[deepspeed,flash-attn]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.23.3->axolotl[deepspeed,flash-attn]) (1.3.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from h2<5,>=3.1.0->grpclib==0.4.7->modal==0.70.5->axolotl[deepspeed,flash-attn]) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from h2<5,>=3.1.0->grpclib==0.4.7->modal==0.70.5->axolotl[deepspeed,flash-attn]) (4.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (2025.2)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from responses<0.19->evaluate==0.4.1->axolotl[deepspeed,flash-attn]) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->axolotl[deepspeed,flash-attn]) (3.4.2)\n",
      "Requirement already satisfied: sigtools>=4.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from synchronicity~=0.9.8->modal==0.70.5->axolotl[deepspeed,flash-attn]) (4.0.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.23.3->axolotl[deepspeed,flash-attn]) (1.5.4)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.34.0)\n",
      "Requirement already satisfied: azure-datalake-store<0.1,>=0.0.53 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.0.53)\n",
      "Requirement already satisfied: azure-identity in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.23.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (12.25.1)\n",
      "Requirement already satisfied: cffi in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.17.1)\n",
      "Requirement already satisfied: msal<2,>=1.16.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.32.3)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.10.1)\n",
      "Requirement already satisfied: cryptography<47,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (44.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (1.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.5.1->axolotl[deepspeed,flash-attn]) (1.20.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from azure-storage-blob>=12.17.0->adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.7.2)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.22)\n",
      "Requirement already satisfied: decorator>4.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (5.2.1)\n",
      "Requirement already satisfied: google-auth>=1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-storage in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (3.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.6.1)\n",
      "Requirement already satisfied: httpcore==1.* in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.24.1->gradio==5.23.3->axolotl[deepspeed,flash-attn]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.23.3->axolotl[deepspeed,flash-attn]) (0.16.0)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=17.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl[deepspeed,flash-attn]) (24.3.0)\n",
      "Requirement already satisfied: circuitbreaker<3.0.0,>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl[deepspeed,flash-attn]) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=12.0.0->modal==0.70.5->axolotl[deepspeed,flash-attn]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=12.0.0->modal==0.70.5->axolotl[deepspeed,flash-attn]) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->modal==0.70.5->axolotl[deepspeed,flash-attn]) (0.1.2)\n",
      "Requirement already satisfied: absl-py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (2.3.0)\n",
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (3.9.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.23.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.38.28,>=1.38.23 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.38.27)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.17.2)\n",
      "Requirement already satisfied: portalocker in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (3.1.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (0.9.0)\n",
      "Requirement already satisfied: lxml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (5.4.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from azure-identity->adlfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from coloredlogs->optimum==1.16.2->axolotl[deepspeed,flash-attn]) (10.0)\n",
      "Requirement already satisfied: cmake>=3.24 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from deepspeed-kernels->axolotl[deepspeed,flash-attn]) (4.0.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (3.2.2)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.70.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.26.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from numba->axolotl[deepspeed,flash-attn]) (0.44.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (78.1.1)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (3.2.3)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (1.3.4)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.7->axolotl[deepspeed,flash-attn]) (5.2.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (1.72.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (3.1.3)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb->axolotl[deepspeed,flash-attn]) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb->axolotl[deepspeed,flash-attn]) (4.3.8)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb->axolotl[deepspeed,flash-attn]) (2.30.0)\n",
      "Requirement already satisfied: setproctitle in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb->axolotl[deepspeed,flash-attn]) (1.3.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl[deepspeed,flash-attn]) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl[deepspeed,flash-attn]) (5.0.2)\n",
      "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.6.0\n",
      "    Uninstalling datasets-3.6.0:\n",
      "      Successfully uninstalled datasets-3.6.0\n",
      "Successfully installed datasets-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_HOME=/usr/local/cuda && \\\n",
    " export PATH=$CUDA_HOME/bin:$PATH && \\\n",
    " export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH && \\\n",
    " pip install --no-build-isolation 'axolotl[flash-attn,deepspeed]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ffa3d4-3276-4a03-94e0-ec0d7f8c1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86266e97-41fb-4ab3-ad09-da51a31b19c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f701f43f4cd14b1284459fa382ad3abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ef1485-2089-4fa4-a7bd-469b8f1260a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"capstone-research/travel-customer-support-chatbot-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83de7b8-874d-4079-897b-f380d7ed9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_messages_to_conversations(messages):\n",
    "    \"\"\"Convert messages to Axolotl-compatible conversation format.\"\"\"\n",
    "    conversations = []\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "\n",
    "        mapped_role = \"user\" if role == \"user\" else (\"assistant\" if role == \"assistant\" else \"system\")\n",
    "\n",
    "        conversations.append({\n",
    "            \"from\": mapped_role,\n",
    "            \"value\": content\n",
    "        })\n",
    "\n",
    "    return {\"conversations\": conversations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7a8733-8556-41c3-8169-eeedf200f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /system/environment/dataset /system/environment/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cbd93fc-70bf-4426-9a0b-b307c161e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_save_dataset(datafile):\n",
    "    dataset = load_dataset(\"capstone-research/travel-customer-support-chatbot-dataset\")\n",
    "\n",
    "    with open(f\"/system/environment/dataset/{datafile}.jsonl\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for example in dataset[datafile]:\n",
    "            messages = example.get(\"messages\", [])\n",
    "            if messages:\n",
    "                converted = convert_messages_to_conversations(messages)\n",
    "                json.dump(converted, outfile, ensure_ascii=False)\n",
    "                outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef121687-ac76-41c0-abda-83ef14728974",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_and_save_dataset(\"train\")\n",
    "convert_and_save_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f701f2b1-b3a2-41fd-b7cc-56de3a683838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /teamspace/studios/this_studio/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aa8721f-3f5c-4758-9763-b94ecee9ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_string = \"\"\"\n",
    "base_model: openchat/openchat_3.5\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: true\n",
    "load_in_4bit: false\n",
    "\n",
    "datasets:\n",
    "  - path: /system/environment/dataset/train.jsonl\n",
    "    type: chat_template\n",
    "    chat_template: chatml\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "    roles_to_train: [\"assistant\"]\n",
    "    train_on_eos: turn\n",
    "    train_on_eot: turn\n",
    "    message_field_training: train\n",
    "\n",
    "evals:\n",
    "  - path: /system/environment/dataset/test.jsonl\n",
    "    type: chat_template\n",
    "    chat_template: chatml\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "remove_unused_columns: false\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "adapter: lora\n",
    "lora_model_dir:\n",
    "lora_r: 32\n",
    "lora_alpha: 16\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "lora_modules_to_save:\n",
    "  - embed_tokens\n",
    "  - lm_head\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "num_epochs: 3\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "bf16: auto\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true\n",
    "resume_from_checkpoint:\n",
    "logging_steps: 1\n",
    "flash_attention: true\n",
    "\n",
    "wandb_project: travel-chat-assistant\n",
    "wandb_entity: harshit-sk-org\n",
    "wandb_watch: all\n",
    "wandb_name: openchat-travel-customer-support-v1\n",
    "wandb_log_model: checkpoint\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 1\n",
    "saves_per_epoch: 1\n",
    "weight_decay: 0.0\n",
    "\n",
    "special_tokens:\n",
    "  bos_token: \"<|im_start|>\"\n",
    "  eos_token: \"<|im_end|>\"\n",
    "\n",
    "tokens:\n",
    "  - \"<|user|>\"\n",
    "  - \"<|assistant|>\"\n",
    "  - \"<|im_start|>\"\n",
    "  - \"<|im_end|>\"\n",
    "\n",
    "output_dir: /system/environment/output\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Convert the YAML string to a Python dictionary\n",
    "yaml_dict = yaml.safe_load(yaml_string)\n",
    "\n",
    "# Specify your file path\n",
    "file_path = 'openchat_lora.yaml'\n",
    "\n",
    "# Write the YAML file\n",
    "with open(file_path, 'w') as file:\n",
    "    yaml.dump(yaml_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40e062-1dd1-4cb8-8112-12f4ce1f897d",
   "metadata": {},
   "source": [
    "Above we have a configuration file with base LLM model and datasets specified, among many other things. Axolotl can automatically detect whether the specified datasets are on HuggingFace repo or local machine.\n",
    "\n",
    "The Axolotl configuration options encompass model and dataset selection, data pre-processing, and training. Let's go through them line by line:\n",
    "\n",
    "*   \"base model\": String value, specifies the underlying pre-trained LLM that will be used for finetuning\n",
    "\n",
    "Next we have options for model weights quantization. Quantization allows for reduction in occupied memory on GPUs.\n",
    "\n",
    "*   \"load_in_8bit\": Boolean value, whether to quantize the model weights into 8-bit integer.\n",
    "\n",
    "*   \"load_in_4bit\": Boolean value, whether to quantize the model weights into 4-bit integer.\n",
    "\n",
    "*   \"strict\": Boolean value. If false, it allows for overriding established configuration options in the yaml file when executing in command-line interface.\n",
    "\n",
    "*   \"datasets\": a list of dicts that contain path and type of data sets as well as other optional configurations where datasets are concerned. Supports multiple datasets.\n",
    "\n",
    "*   \"val_set_size\": Either a float value less than one or an integer less than the total size of dataset. Sets the size of validation set from the whole dataset. If float, sets the proportion of the dataset assigned for validation. If integer, sets the direct size of validation set.\n",
    "\n",
    "*   \"output_dir\": String value. Path of trained model.\n",
    "\n",
    "For data preprocessing:\n",
    "\n",
    "*   \"sequence_len\": Integer. Specifies the maximum sequence length of the input. Typically 2048 or less.\n",
    "\n",
    "*   \"pad_to_sequence_len\": Boolean. Padding input to maximum sequence length.\n",
    "\n",
    "*   \"sample_packing\": Boolean. Specifies whether to use multi-packing with block diagonal attention.\n",
    "\n",
    "*   \"special_tokens\": Python dict, optional. Allows users to specify the additional special tokens to be ignored by the tokenizer.\n",
    "\n",
    "For LoRA configuration and its hyperparamters:\n",
    "\n",
    "*   \"adapter\": String. Either \"lora\" or \"qlora\", depending on user's choice.\n",
    "\n",
    "*   \"lora_model_dir\": String, Optional. Path to directory that contains LoRA model, if there is already a trained LoRA model the user would like to use.\n",
    "\n",
    "*   \"lora_r\": Integer. Refers to the rank of LoRA decomposition matrices. Higher value will reduce LoRA efficiency. Recommended to be set to 8.\n",
    "\n",
    "*   \"lora_alpha\": Integer. Scale the weight matrices by $\\frac{\\text{lora_alpha}}{\\text{lora_r}}$Recommended to be fixed at 16.\n",
    "\n",
    "*   \"lora_dropout\": Float that is 1 or less. The dropout probability of a lora layer.\n",
    "\n",
    "*   \"lora_target_linear\": Boolean. If true, lora will target all linear modules in the transformers architecture.\n",
    "\n",
    "*   \"lora_modules_to_save\": If you added new tokens to the tokenizer, you may need to save some LoRA modules because they need to know the new tokens.\n",
    "\n",
    "See [LoRA](https://arxiv.org/abs/2106.09685) for detailed explanation of LoRA implementation.\n",
    "\n",
    "For the training configurations:\n",
    "\n",
    "*   \"gradient_accumulation_steps\": Integer. The number of steps over which to accumulate gradient for batch training. E.g. if 2, backprop is performed every two steps.\n",
    "\n",
    "*   \"micro_batch_size\": Integer. Batch size per gpu / gradient_accumulation_steps\n",
    "\n",
    "*   \"num_epochs\": Integer. Number of epochs. One epoch is when training has looped over every batch in the whole data set once.\n",
    "\n",
    "*   \"optimizer\": The optimizer to use for the training.\n",
    "\n",
    "*   \"learning_rate\": The learning rate.\n",
    "\n",
    "*   \"lr_scheduler\": The learning rate scheduler to use for adjusting learning rate during training.\n",
    "\n",
    "*   \"train_on_inputs\": Boolean. Whether to ignore or include the user's prompt from the training labels.\n",
    "\n",
    "*   \"group_by_length\": Boolean. Whether to group similarly sized data to minimize padding.\n",
    "\n",
    "*   \"bf16\": Either \"auto\", \"true\", or \"false\". Whether to use CUDA bf16 floating point format. If set to \"auto\", will automatically apply bf16 should the gpu supports it.\n",
    "\n",
    "*   \"fp16\": Optional. Specifies whether to use CUDA fp16. Automatically set to true if \"bf16\" is set to true. Otherwise false.\n",
    "\n",
    "*   \"tf32\": Boolean. Whether to use CUDA tf32. Will override bf16.\n",
    "\n",
    "*   \"gradient_checkpointing\": Boolean. Whether to use gradient checkpointing https://huggingface.co/docs/transformers/v4.18.0/en/performance#gradient-checkpointing\n",
    "\n",
    "*   \"gradient_checkpointing_kwargs\": Python Dict. Fed into the trainer.\n",
    "\n",
    "*   \"logging_steps\": Integer. Log training information over every specified number of steps.\n",
    "\n",
    "*   \"flash_attention\": Boolean. Whether to use the [flash attention](https://github.com/Dao-AILab/flash-attention) mechanism.\n",
    "\n",
    "*   \"sdp_attention\": Boolean. Whether to use the Scaled Dot Product attention mechanism (the attention mechanism in the [original implementation](https://arxiv.org/abs/1706.03762) of transformers.)\n",
    "\n",
    "*   \"warmup_steps\": Integer. The number of pre-training steps where a very low learning rate is used.\n",
    "\n",
    "*   \"evals_per_epoch\": Integer. Number of evaluations to be performed within one training epoch.\n",
    "\n",
    "*   \"saves_per_epoch\": Integer. Number of times the model is saved in one training epoch.\n",
    "\n",
    "*   \"weight_decay\": Positive Float. Sets the \"strength\" of weight decay (i.e. setting the coefficient of L2 regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a080389-810e-4acb-9fe9-37d92d1f2665",
   "metadata": {},
   "source": [
    "The above is but a snippet aiming to get users familiarized with the types of streamlined configuration options axolotl provides. For a full list of configuration options, see [here](https://axolotl-ai-cloud.github.io/axolotl/docs/config.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77399a88-f081-48e4-b0b3-37078b039c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2025-06-14 11:15:46,574] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-06-14 11:15:46,671] [INFO] [root.spawn:77] [PID:4173] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -c /tmp/tmpcfq12rm6/test.c -o /tmp/tmpcfq12rm6/test.o\n",
      "[2025-06-14 11:15:46,968] [INFO] [root.spawn:77] [PID:4173] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat /tmp/tmpcfq12rm6/test.o -laio -o /tmp/tmpcfq12rm6/a.out\n",
      "[2025-06-14 11:15:47,015] [INFO] [root.spawn:77] [PID:4173] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -c /tmp/tmpbtv_5b0z/test.c -o /tmp/tmpbtv_5b0z/test.o\n",
      "[2025-06-14 11:15:47,033] [INFO] [root.spawn:77] [PID:4173] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat /tmp/tmpbtv_5b0z/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpbtv_5b0z/a.out\n",
      "[2025-06-14 11:15:47,902] [INFO] [datasets.<module>:54] [PID:4173] PyTorch version 2.6.0+cu124 available.\n",
      "[2025-06-14 11:15:49,877] [DEBUG] [axolotl.resolve_dtype:65] [PID:4173] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2025-06-14 11:15:49,925] [INFO] [axolotl.normalize_config:237] [PID:4173] [RANK:0] cuda memory usage baseline: 0.000GB (+0.464GB misc)\u001b[39m\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-06-14 11:15:50,117] [DEBUG] [axolotl.utils.models.load_tokenizer:444] [PID:4173] [RANK:0] EOS: 32003 / <|im_end|>\u001b[39m\n",
      "[2025-06-14 11:15:50,117] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:4173] [RANK:0] BOS: 32002 / <|im_start|>\u001b[39m\n",
      "[2025-06-14 11:15:50,117] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:4173] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
      "[2025-06-14 11:15:50,117] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:4173] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
      "[2025-06-14 11:15:50,117] [INFO] [axolotl.utils.models.load_tokenizer:461] [PID:4173] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2025-06-14 11:15:50,117] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:271] [PID:4173] [RANK:0] Unable to find prepared dataset in last_run_prepared/795dcef3d4a8d6f0fdc9d67bb0a1386f\u001b[39m\n",
      "[2025-06-14 11:15:50,117] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:272] [PID:4173] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-06-14 11:15:50,117] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:274] [PID:4173] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2025-06-14 11:15:50,117] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:281] [PID:4173] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "[2025-06-14 11:15:50,174] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:484] [PID:4173] [RANK:0] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
      "[2025-06-14 11:15:50,176] [INFO] [axolotl.__call__:761] [PID:4173] [RANK:0] Using chat template:\n",
      "---\n",
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "---\u001b[39m\n",
      "[2025-06-14 11:15:50,236] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:4173] [RANK:0] min_input_len: 111\u001b[39m\n",
      "[2025-06-14 11:15:50,236] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:4173] [RANK:0] max_input_len: 1190\u001b[39m\n",
      "[2025-06-14 11:15:50,353] [INFO] [axolotl.process_datasets_for_packing:247] [PID:4173] [RANK:0] dropping token_type_ids column if it exists\u001b[39m\n",
      "[2025-06-14 11:15:50,520] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:351] [PID:4173] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/795dcef3d4a8d6f0fdc9d67bb0a1386f\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|█| 2640/2640 [00:00<00:00, 51332.87 exampl\n",
      "[2025-06-14 11:15:50,996] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:434] [PID:4173] [RANK:0] gather_len_batches: [146]\u001b[39m\n",
      "[2025-06-14 11:15:50,996] [INFO] [axolotl.calc_sample_packing_eff_est:491] [PID:4173] [RANK:0] sample_packing_eff_est across ranks: [0.9903037711365582]\u001b[39m\n",
      "[2025-06-14 11:15:51,093] [INFO] [axolotl.utils.models.load_tokenizer:461] [PID:4173] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:20<00:00, 10.49s/it]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "[2025-06-14 11:16:12,634] [INFO] [axolotl.utils.models.load_model:1309] [PID:4173] [RANK:0] cuda memory usage after model load: 6.994GB (+0.578GB cache, +0.884GB misc)\u001b[39m\n",
      "[2025-06-14 11:16:12,656] [INFO] [axolotl.utils.models.prepare_model:1212] [PID:4173] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
      "[2025-06-14 11:16:12,658] [INFO] [axolotl.utils.models.load_model:1348] [PID:4173] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-06-14 11:16:12,661] [INFO] [axolotl.utils.models.load_lora:1542] [PID:4173] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
      "trainable params: 346,079,232 || all params: 7,587,860,480 || trainable%: 4.5610\n",
      "[2025-06-14 11:16:13,385] [INFO] [axolotl.utils.models.load_model:1409] [PID:4173] [RANK:0] cuda memory usage after adapters: 7.798GB (+0.903GB cache, +0.948GB misc)\u001b[39m\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*_args, **kwargs)\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[2025-06-14 11:16:14,208] [INFO] [axolotl.train.save_initial_configs:359] [PID:4173] [RANK:0] Pre-saving adapter config to /system/environment/output...\u001b[39m\n",
      "[2025-06-14 11:16:14,208] [INFO] [axolotl.train.save_initial_configs:363] [PID:4173] [RANK:0] Pre-saving tokenizer to /system/environment/output...\u001b[39m\n",
      "[2025-06-14 11:16:14,231] [INFO] [axolotl.train.save_initial_configs:366] [PID:4173] [RANK:0] Pre-saving model config to /system/environment/output...\u001b[39m\n",
      "[2025-06-14 11:16:14,233] [INFO] [axolotl.train.execute_training:211] [PID:4173] [RANK:0] Starting trainer...\u001b[39m\n",
      "[2025-06-14 11:16:14,512] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:434] [PID:4173] [RANK:0] gather_len_batches: [146]\u001b[39m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharshit-sk\u001b[0m (\u001b[33mharshit-sk-org\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.20.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/wandb/run-20250614_111614-5dv6jghk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mopenchat-travel-customer-support-v1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/harshit-sk-org/travel-chat-assistant\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/harshit-sk-org/travel-chat-assistant/runs/5dv6jghk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "[2025-06-14 11:16:15,615] [INFO] [axolotl.callbacks.on_train_begin:812] [PID:4173] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
      "  0%|                                                   | 0/108 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 1.8731, 'grad_norm': 2660.5283203125, 'learning_rate': 0.0, 'epoch': 0.03}\n",
      "  1%|▍                                          | 1/108 [00:19<35:35, 19.96s/it][2025-06-14 11:16:54,864] [INFO] [axolotl.callbacks.on_step_end:128] [PID:4173] [RANK:0] cuda memory usage while training: 13.377GB (+8.893GB cache, +0.981GB misc)\u001b[39m\n",
      "{'loss': 1.7806, 'grad_norm': 1522.64306640625, 'learning_rate': 2e-05, 'epoch': 0.05}\n",
      "{'loss': 1.3973, 'grad_norm': 63.96414566040039, 'learning_rate': 4e-05, 'epoch': 0.08}\n",
      "{'loss': 1.1982, 'grad_norm': 8.163189888000488, 'learning_rate': 6e-05, 'epoch': 0.11}\n",
      "{'loss': 1.0102, 'grad_norm': 5.053516864776611, 'learning_rate': 8e-05, 'epoch': 0.14}\n",
      "{'loss': 0.8683, 'grad_norm': 6.47304105758667, 'learning_rate': 0.0001, 'epoch': 0.16}\n",
      "{'loss': 0.7435, 'grad_norm': 3.787416696548462, 'learning_rate': 0.00012, 'epoch': 0.19}\n",
      "{'loss': 0.6562, 'grad_norm': 2.678243637084961, 'learning_rate': 0.00014, 'epoch': 0.22}\n",
      "{'loss': 0.6293, 'grad_norm': 3.055309295654297, 'learning_rate': 0.00016, 'epoch': 0.25}\n",
      "{'loss': 0.6111, 'grad_norm': 2.3260157108306885, 'learning_rate': 0.00018, 'epoch': 0.27}\n",
      "{'loss': 0.616, 'grad_norm': 2.599917411804199, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
      "{'loss': 0.5847, 'grad_norm': 2.1547787189483643, 'learning_rate': 0.0001999486216200688, 'epoch': 0.33}\n",
      "{'loss': 0.5781, 'grad_norm': 2.0187008380889893, 'learning_rate': 0.00019979453927503364, 'epoch': 0.36}\n",
      "{'loss': 0.5988, 'grad_norm': 1.7962313890457153, 'learning_rate': 0.00019953791129491983, 'epoch': 0.38}\n",
      "{'loss': 0.5636, 'grad_norm': 1.9933156967163086, 'learning_rate': 0.0001991790013823246, 'epoch': 0.41}\n",
      "{'loss': 0.5198, 'grad_norm': 1.95453941822052, 'learning_rate': 0.00019871817834144504, 'epoch': 0.44}\n",
      "{'loss': 0.4869, 'grad_norm': 1.924361228942871, 'learning_rate': 0.00019815591569910654, 'epoch': 0.47}\n",
      "{'loss': 0.5288, 'grad_norm': 1.7928416728973389, 'learning_rate': 0.00019749279121818235, 'epoch': 0.49}\n",
      "{'loss': 0.4883, 'grad_norm': 1.4212778806686401, 'learning_rate': 0.00019672948630390294, 'epoch': 0.52}\n",
      "{'loss': 0.5052, 'grad_norm': 1.5379763841629028, 'learning_rate': 0.00019586678530366606, 'epoch': 0.55}\n",
      "{'loss': 0.4895, 'grad_norm': 1.2710984945297241, 'learning_rate': 0.00019490557470106686, 'epoch': 0.58}\n",
      "{'loss': 0.5413, 'grad_norm': 1.4468929767608643, 'learning_rate': 0.00019384684220497605, 'epoch': 0.6}\n",
      "{'loss': 0.4823, 'grad_norm': 1.234697937965393, 'learning_rate': 0.0001926916757346022, 'epoch': 0.63}\n",
      "{'loss': 0.5588, 'grad_norm': 1.257185935974121, 'learning_rate': 0.00019144126230158127, 'epoch': 0.66}\n",
      "{'loss': 0.5065, 'grad_norm': 1.1207894086837769, 'learning_rate': 0.0001900968867902419, 'epoch': 0.68}\n",
      "{'loss': 0.4757, 'grad_norm': 1.0474392175674438, 'learning_rate': 0.00018865993063730004, 'epoch': 0.71}\n",
      "{'loss': 0.4478, 'grad_norm': 1.233203411102295, 'learning_rate': 0.00018713187041233896, 'epoch': 0.74}\n",
      "{'loss': 0.5329, 'grad_norm': 1.1855186223983765, 'learning_rate': 0.00018551427630053463, 'epoch': 0.77}\n",
      "{'loss': 0.4785, 'grad_norm': 1.047416090965271, 'learning_rate': 0.00018380881048918405, 'epoch': 0.79}\n",
      "{'loss': 0.4748, 'grad_norm': 1.0838350057601929, 'learning_rate': 0.0001820172254596956, 'epoch': 0.82}\n",
      "{'loss': 0.44, 'grad_norm': 0.9367715716362, 'learning_rate': 0.00018014136218679567, 'epoch': 0.85}\n",
      "{'loss': 0.4672, 'grad_norm': 1.5572515726089478, 'learning_rate': 0.000178183148246803, 'epoch': 0.88}\n",
      "{'loss': 0.4347, 'grad_norm': 1.0211114883422852, 'learning_rate': 0.00017614459583691346, 'epoch': 0.9}\n",
      "{'loss': 0.5019, 'grad_norm': 1.0754083395004272, 'learning_rate': 0.00017402779970753155, 'epoch': 0.93}\n",
      "{'loss': 0.4717, 'grad_norm': 0.9597083926200867, 'learning_rate': 0.00017183493500977278, 'epoch': 0.96}\n",
      "{'loss': 0.4373, 'grad_norm': 0.9033434391021729, 'learning_rate': 0.00016956825506034867, 'epoch': 0.99}\n",
      " 33%|██████████████                            | 36/108 [15:08<24:50, 20.70s/it]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/system/environment/output/checkpoint-36)... Done. 7.4s\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.4004, 'grad_norm': 1.2697741985321045, 'learning_rate': 0.0001672300890261317, 'epoch': 1.0}\n",
      "{'loss': 0.3496, 'grad_norm': 0.9028515219688416, 'learning_rate': 0.00016482283953077887, 'epoch': 1.03}\n",
      "{'loss': 0.3817, 'grad_norm': 0.8944099545478821, 'learning_rate': 0.00016234898018587337, 'epoch': 1.05}\n",
      "{'loss': 0.3538, 'grad_norm': 0.8554709553718567, 'learning_rate': 0.00015981105304912162, 'epoch': 1.08}\n",
      "{'loss': 0.3768, 'grad_norm': 0.970249354839325, 'learning_rate': 0.00015721166601221698, 'epoch': 1.11}\n",
      "{'loss': 0.3545, 'grad_norm': 0.9734548926353455, 'learning_rate': 0.00015455349012105486, 'epoch': 1.14}\n",
      "{'loss': 0.3576, 'grad_norm': 0.9393885135650635, 'learning_rate': 0.00015183925683105254, 'epoch': 1.16}\n",
      "{'loss': 0.3704, 'grad_norm': 0.9139907956123352, 'learning_rate': 0.0001490717552003938, 'epoch': 1.19}\n",
      "{'loss': 0.3681, 'grad_norm': 1.0047688484191895, 'learning_rate': 0.00014625382902408356, 'epoch': 1.22}\n",
      "{'loss': 0.374, 'grad_norm': 1.0308648347854614, 'learning_rate': 0.00014338837391175582, 'epoch': 1.25}\n",
      "{'loss': 0.3765, 'grad_norm': 1.000518560409546, 'learning_rate': 0.00014047833431223938, 'epoch': 1.27}\n",
      "{'loss': 0.3536, 'grad_norm': 0.839834451675415, 'learning_rate': 0.00013752670048793744, 'epoch': 1.3}\n",
      "{'loss': 0.3392, 'grad_norm': 1.012284755706787, 'learning_rate': 0.00013453650544213076, 'epoch': 1.33}\n",
      "{'loss': 0.3509, 'grad_norm': 0.8876793384552002, 'learning_rate': 0.0001315108218023621, 'epoch': 1.36}\n",
      "{'loss': 0.3826, 'grad_norm': 0.9305344820022583, 'learning_rate': 0.00012845275866310324, 'epoch': 1.38}\n",
      "{'loss': 0.3516, 'grad_norm': 0.9223380088806152, 'learning_rate': 0.00012536545839095074, 'epoch': 1.41}\n",
      "{'loss': 0.3405, 'grad_norm': 0.8888311982154846, 'learning_rate': 0.00012225209339563145, 'epoch': 1.44}\n",
      "{'loss': 0.367, 'grad_norm': 0.8730847239494324, 'learning_rate': 0.00011911586287013725, 'epoch': 1.47}\n",
      "{'loss': 0.3466, 'grad_norm': 0.8347588777542114, 'learning_rate': 0.00011595998950333793, 'epoch': 1.49}\n",
      "{'loss': 0.3332, 'grad_norm': 2.410275459289551, 'learning_rate': 0.00011278771616845061, 'epoch': 1.52}\n",
      "{'loss': 0.3461, 'grad_norm': 0.9236244559288025, 'learning_rate': 0.00010960230259076818, 'epoch': 1.55}\n",
      "{'loss': 0.369, 'grad_norm': 0.8574447631835938, 'learning_rate': 0.0001064070219980713, 'epoch': 1.58}\n",
      "{'loss': 0.3336, 'grad_norm': 0.8524020314216614, 'learning_rate': 0.00010320515775716555, 'epoch': 1.6}\n",
      "{'loss': 0.3561, 'grad_norm': 0.805962324142456, 'learning_rate': 0.0001, 'epoch': 1.63}\n",
      "{'loss': 0.3482, 'grad_norm': 0.8420650362968445, 'learning_rate': 9.679484224283449e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3599, 'grad_norm': 0.9066621661186218, 'learning_rate': 9.359297800192872e-05, 'epoch': 1.68}\n",
      "{'loss': 0.3458, 'grad_norm': 0.9219955205917358, 'learning_rate': 9.039769740923183e-05, 'epoch': 1.71}\n",
      "{'loss': 0.341, 'grad_norm': 0.8082414865493774, 'learning_rate': 8.721228383154939e-05, 'epoch': 1.74}\n",
      "{'loss': 0.3433, 'grad_norm': 0.7742849588394165, 'learning_rate': 8.404001049666211e-05, 'epoch': 1.77}\n",
      "{'loss': 0.3235, 'grad_norm': 0.8048144578933716, 'learning_rate': 8.08841371298628e-05, 'epoch': 1.79}\n",
      "{'loss': 0.321, 'grad_norm': 0.9038287997245789, 'learning_rate': 7.774790660436858e-05, 'epoch': 1.82}\n",
      "{'loss': 0.3531, 'grad_norm': 0.8712989091873169, 'learning_rate': 7.463454160904928e-05, 'epoch': 1.85}\n",
      "{'loss': 0.3213, 'grad_norm': 0.7670961618423462, 'learning_rate': 7.154724133689677e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3347, 'grad_norm': 0.794897198677063, 'learning_rate': 6.848917819763793e-05, 'epoch': 1.9}\n",
      "{'loss': 0.3312, 'grad_norm': 0.802561342716217, 'learning_rate': 6.546349455786926e-05, 'epoch': 1.93}\n",
      "{'loss': 0.3322, 'grad_norm': 0.7866290807723999, 'learning_rate': 6.24732995120626e-05, 'epoch': 1.96}\n",
      " 67%|████████████████████████████              | 72/108 [31:28<11:44, 19.57s/it]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/system/environment/output/checkpoint-72)... Done. 7.3s\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.3412, 'grad_norm': 0.8175866007804871, 'learning_rate': 5.952166568776062e-05, 'epoch': 1.99}\n",
      "{'loss': 0.3567, 'grad_norm': 1.2989399433135986, 'learning_rate': 5.6611626088244194e-05, 'epoch': 2.0}\n",
      "{'loss': 0.283, 'grad_norm': 0.7743635773658752, 'learning_rate': 5.37461709759165e-05, 'epoch': 2.03}\n",
      "{'loss': 0.2664, 'grad_norm': 0.6969102621078491, 'learning_rate': 5.092824479960625e-05, 'epoch': 2.05}\n",
      "{'loss': 0.273, 'grad_norm': 0.714819073677063, 'learning_rate': 4.8160743168947496e-05, 'epoch': 2.08}\n",
      "{'loss': 0.252, 'grad_norm': 0.704871654510498, 'learning_rate': 4.544650987894514e-05, 'epoch': 2.11}\n",
      "{'loss': 0.2743, 'grad_norm': 0.7376236915588379, 'learning_rate': 4.278833398778306e-05, 'epoch': 2.14}\n",
      "{'loss': 0.2632, 'grad_norm': 0.7106558084487915, 'learning_rate': 4.0188946950878404e-05, 'epoch': 2.16}\n",
      "{'loss': 0.272, 'grad_norm': 0.7691617608070374, 'learning_rate': 3.7651019814126654e-05, 'epoch': 2.19}\n",
      "{'loss': 0.2543, 'grad_norm': 0.7144562005996704, 'learning_rate': 3.517716046922118e-05, 'epoch': 2.22}\n",
      "{'loss': 0.255, 'grad_norm': 0.7318939566612244, 'learning_rate': 3.276991097386831e-05, 'epoch': 2.25}\n",
      "{'loss': 0.2544, 'grad_norm': 0.7645682096481323, 'learning_rate': 3.0431744939651364e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2499, 'grad_norm': 0.7177962064743042, 'learning_rate': 2.8165064990227252e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2773, 'grad_norm': 0.771493673324585, 'learning_rate': 2.5972200292468464e-05, 'epoch': 2.33}\n",
      "{'loss': 0.2673, 'grad_norm': 0.7732207775115967, 'learning_rate': 2.3855404163086558e-05, 'epoch': 2.36}\n",
      "{'loss': 0.2528, 'grad_norm': 0.7595717310905457, 'learning_rate': 2.181685175319702e-05, 'epoch': 2.38}\n",
      "{'loss': 0.2626, 'grad_norm': 0.776347279548645, 'learning_rate': 1.985863781320435e-05, 'epoch': 2.41}\n",
      "{'loss': 0.2795, 'grad_norm': 0.813409149646759, 'learning_rate': 1.7982774540304403e-05, 'epoch': 2.44}\n",
      "{'loss': 0.2463, 'grad_norm': 0.7671748995780945, 'learning_rate': 1.619118951081594e-05, 'epoch': 2.47}\n",
      "{'loss': 0.2529, 'grad_norm': 0.7685192823410034, 'learning_rate': 1.4485723699465392e-05, 'epoch': 2.49}\n",
      "{'loss': 0.2638, 'grad_norm': 0.7426058650016785, 'learning_rate': 1.286812958766106e-05, 'epoch': 2.52}\n",
      "{'loss': 0.2395, 'grad_norm': 0.6812983751296997, 'learning_rate': 1.134006936269999e-05, 'epoch': 2.55}\n",
      "{'loss': 0.2571, 'grad_norm': 0.7280789017677307, 'learning_rate': 9.903113209758096e-06, 'epoch': 2.58}\n",
      "{'loss': 0.2498, 'grad_norm': 0.7502626776695251, 'learning_rate': 8.558737698418761e-06, 'epoch': 2.6}\n",
      "{'loss': 0.2628, 'grad_norm': 0.7316575050354004, 'learning_rate': 7.308324265397836e-06, 'epoch': 2.63}\n",
      "{'loss': 0.2507, 'grad_norm': 0.7794380187988281, 'learning_rate': 6.153157795023956e-06, 'epoch': 2.66}\n",
      "{'loss': 0.2619, 'grad_norm': 0.720770001411438, 'learning_rate': 5.094425298933136e-06, 'epoch': 2.68}\n",
      "{'loss': 0.2465, 'grad_norm': 0.7494491338729858, 'learning_rate': 4.133214696333942e-06, 'epoch': 2.71}\n",
      "{'loss': 0.2557, 'grad_norm': 0.7407036423683167, 'learning_rate': 3.270513696097055e-06, 'epoch': 2.74}\n",
      "{'loss': 0.274, 'grad_norm': 0.7694376111030579, 'learning_rate': 2.5072087818176382e-06, 'epoch': 2.77}\n",
      "{'loss': 0.2518, 'grad_norm': 0.7272924780845642, 'learning_rate': 1.8440843008934561e-06, 'epoch': 2.79}\n",
      "{'loss': 0.2621, 'grad_norm': 0.7111788392066956, 'learning_rate': 1.2818216585549825e-06, 'epoch': 2.82}\n",
      "{'loss': 0.2578, 'grad_norm': 0.7284103035926819, 'learning_rate': 8.209986176753948e-07, 'epoch': 2.85}\n",
      "{'loss': 0.2537, 'grad_norm': 0.7223151922225952, 'learning_rate': 4.62088705080177e-07, 'epoch': 2.88}\n",
      "{'loss': 0.2567, 'grad_norm': 0.769940197467804, 'learning_rate': 2.054607249663665e-07, 'epoch': 2.9}\n",
      "{'loss': 0.2659, 'grad_norm': 0.7660389542579651, 'learning_rate': 5.137837993121064e-08, 'epoch': 2.93}\n",
      "100%|█████████████████████████████████████████| 108/108 [51:15<00:00, 24.61s/it]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/system/environment/output/checkpoint-108)... Done. 7.8s\n",
      "{'train_runtime': 3158.6558, 'train_samples_per_second': 2.507, 'train_steps_per_second': 0.034, 'train_loss': 0.4278794172461386, 'epoch': 2.93}\n",
      "100%|█████████████████████████████████████████| 108/108 [52:37<00:00, 24.61s/it]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 108/108 [54:01<00:00, 30.02s/it]\n",
      "[2025-06-14 12:10:17,249] [INFO] [axolotl.train.save_trained_model:231] [PID:4173] [RANK:0] Training completed! Saving pre-trained model to /system/environment/output.\u001b[39m\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mopenchat-travel-customer-support-v1\u001b[0m at: \u001b[34mhttps://wandb.ai/harshit-sk-org/travel-chat-assistant/runs/5dv6jghk\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250614_111614-5dv6jghk/logs\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m axolotl.cli.train openchat_lora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a6470a-86bc-475c-af09-b633c88b354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-14 12:10:44,009] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-06-14 12:10:44,087] [INFO] [root.spawn:77] [PID:38285] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -c /tmp/tmp46u_qzjq/test.c -o /tmp/tmp46u_qzjq/test.o\n",
      "[2025-06-14 12:10:44,104] [INFO] [root.spawn:77] [PID:38285] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat /tmp/tmp46u_qzjq/test.o -laio -o /tmp/tmp46u_qzjq/a.out\n",
      "[2025-06-14 12:10:44,118] [INFO] [root.spawn:77] [PID:38285] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -c /tmp/tmpdt1yvv1a/test.c -o /tmp/tmpdt1yvv1a/test.o\n",
      "[2025-06-14 12:10:44,135] [INFO] [root.spawn:77] [PID:38285] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat /tmp/tmpdt1yvv1a/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpdt1yvv1a/a.out\n",
      "[2025-06-14 12:10:44,638] [INFO] [numexpr.utils._init_num_threads:164] [PID:38285] NumExpr defaulting to 16 threads.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/click/core.py:1193: UserWarning: The parameter --merge-lora is used more than once. Remove its duplicate as parameters should be unique.\n",
      "  parser = self.make_parser(ctx)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/click/core.py:1186: UserWarning: The parameter --merge-lora is used more than once. Remove its duplicate as parameters should be unique.\n",
      "  self.parse_args(ctx, args)\n",
      "[2025-06-14 12:10:45,215] [INFO] [datasets.<module>:54] [PID:38285] PyTorch version 2.6.0+cu124 available.\n",
      "\u001b[33m[2025-06-14 12:10:46,938] [WARNING] [axolotl.utils.schemas.config.check_sample_packing_wo_flash:467] [PID:38285] [RANK:0] sample_packing without flash, sdp, xformers or flex attention does not handle cross sample decontamination.\u001b[39m\n",
      "\u001b[33m[2025-06-14 12:10:46,938] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:846] [PID:38285] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2025-06-14 12:10:46,988] [DEBUG] [axolotl.resolve_dtype:65] [PID:38285] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2025-06-14 12:10:47,028] [INFO] [axolotl.normalize_config:237] [PID:38285] [RANK:0] cuda memory usage baseline: 0.000GB (+0.464GB misc)\u001b[39m\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-06-14 12:10:47,062] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:317] [PID:38285] [RANK:0] loading tokenizer... openchat/openchat_3.5\u001b[39m\n",
      "[2025-06-14 12:10:47,369] [DEBUG] [axolotl.utils.models.load_tokenizer:444] [PID:38285] [RANK:0] EOS: 32003 / <|im_end|>\u001b[39m\n",
      "[2025-06-14 12:10:47,369] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:38285] [RANK:0] BOS: 32002 / <|im_start|>\u001b[39m\n",
      "[2025-06-14 12:10:47,369] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:38285] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
      "[2025-06-14 12:10:47,369] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:38285] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
      "[2025-06-14 12:10:47,369] [INFO] [axolotl.utils.models.load_tokenizer:461] [PID:38285] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2025-06-14 12:10:47,369] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:320] [PID:38285] [RANK:0] loading model...\u001b[39m\n",
      "[2025-06-14 12:10:47,562] [INFO] [accelerate.utils.modeling.get_balanced_memory:990] [PID:38285] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.43s/it]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "[2025-06-14 12:10:50,504] [INFO] [axolotl.utils.models.load_model:1309] [PID:38285] [RANK:0] cuda memory usage after model load: 13.489GB (+0.496GB cache, +0.884GB misc)\u001b[39m\n",
      "[2025-06-14 12:10:50,526] [INFO] [axolotl.utils.models.load_model:1348] [PID:38285] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-06-14 12:10:50,528] [INFO] [axolotl.utils.models.load_lora:1542] [PID:38285] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
      "[2025-06-14 12:10:50,528] [DEBUG] [axolotl.utils.models.load_lora:1593] [PID:38285] [RANK:0] Loading pretrained PEFT - LoRA\u001b[39m\n",
      "trainable params: 346,079,232 || all params: 7,587,860,480 || trainable%: 4.5610\n",
      "[2025-06-14 12:10:56,273] [INFO] [axolotl.utils.models.load_model:1409] [PID:38285] [RANK:0] cuda memory usage after adapters: 14.290GB (+1.788GB cache, +0.948GB misc)\u001b[39m\n",
      "[2025-06-14 12:10:57,021] [INFO] [axolotl.cli.merge_lora.do_merge_lora:33] [PID:38285] [RANK:0] Running merge of LoRA with base model...\u001b[39m\n",
      "Unloading and merging model: 100%|██████████| 653/653 [00:00<00:00, 5023.51it/s]\n",
      "[2025-06-14 12:10:57,156] [INFO] [axolotl.cli.merge_lora.do_merge_lora:46] [PID:38285] [RANK:0] Saving merged model to: /system/environment/output/merged...\u001b[39m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!axolotl merge-lora openchat_lora.yaml --lora-model-dir=\"/system/environment/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9146e103-13ce-45d6-8143-c49d5e9a9a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58a8a9e21c84de8a0f586509403b445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/14.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/capstone-research/OpenChat-3.5-Travel-ChatBot/commit/ad9b53fa6251fd61ded046f47c9af6ef415c5191', commit_message='Upload folder using huggingface_hub', commit_description='', oid='ad9b53fa6251fd61ded046f47c9af6ef415c5191', pr_url=None, repo_url=RepoUrl('https://huggingface.co/capstone-research/OpenChat-3.5-Travel-ChatBot', endpoint='https://huggingface.co', repo_type='model', repo_id='capstone-research/OpenChat-3.5-Travel-ChatBot'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi(token=\"\")\n",
    "api.upload_folder(\n",
    "    folder_path=\"/system/environment/output/merged\",\n",
    "    repo_id=\"capstone-research/OpenChat-3.5-Travel-ChatBot\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd3e60-a7cf-4809-b4be-f4e52b0065dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-14 13:01:50,359] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-06-14 13:01:50,435] [INFO] [root.spawn:77] [PID:67056] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -c /tmp/tmphnncraiv/test.c -o /tmp/tmphnncraiv/test.o\n",
      "[2025-06-14 13:01:50,453] [INFO] [root.spawn:77] [PID:67056] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat /tmp/tmphnncraiv/test.o -laio -o /tmp/tmphnncraiv/a.out\n",
      "[2025-06-14 13:01:50,467] [INFO] [root.spawn:77] [PID:67056] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -O2 -isystem /home/zeus/miniconda3/envs/cloudspace/include -fPIC -c /tmp/tmp1lal48ls/test.c -o /tmp/tmp1lal48ls/test.o\n",
      "[2025-06-14 13:01:50,484] [INFO] [root.spawn:77] [PID:67056] gcc -pthread -B /home/zeus/miniconda3/envs/cloudspace/compiler_compat /tmp/tmp1lal48ls/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp1lal48ls/a.out\n",
      "[2025-06-14 13:01:50,976] [INFO] [numexpr.utils._init_num_threads:164] [PID:67056] NumExpr defaulting to 16 threads.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/click/core.py:1193: UserWarning: The parameter --merge-lora is used more than once. Remove its duplicate as parameters should be unique.\n",
      "  parser = self.make_parser(ctx)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/click/core.py:1186: UserWarning: The parameter --merge-lora is used more than once. Remove its duplicate as parameters should be unique.\n",
      "  self.parse_args(ctx, args)\n",
      "[2025-06-14 13:01:51,550] [INFO] [datasets.<module>:54] [PID:67056] PyTorch version 2.6.0+cu124 available.\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-06-14 13:01:53,345] [DEBUG] [axolotl.resolve_dtype:65] [PID:67056] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2025-06-14 13:01:53,347] [INFO] [axolotl.normalize_config:237] [PID:67056] [RANK:0] cuda memory usage baseline: 0.000GB (+0.464GB misc)\u001b[39m\n",
      "[2025-06-14 13:01:53,902] [INFO] [httpx._send_single_request:1025] [PID:67056] HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
      "[2025-06-14 13:01:54,910] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:317] [PID:67056] [RANK:0] loading tokenizer... /system/environment/output/merged\u001b[39m\n",
      "[2025-06-14 13:01:54,998] [DEBUG] [axolotl.utils.models.load_tokenizer:444] [PID:67056] [RANK:0] EOS: 32003 / <|im_end|>\u001b[39m\n",
      "[2025-06-14 13:01:54,998] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:67056] [RANK:0] BOS: 32002 / <|im_start|>\u001b[39m\n",
      "[2025-06-14 13:01:54,998] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:67056] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
      "[2025-06-14 13:01:54,998] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:67056] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
      "[2025-06-14 13:01:54,998] [INFO] [axolotl.utils.models.load_tokenizer:461] [PID:67056] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2025-06-14 13:01:54,998] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:320] [PID:67056] [RANK:0] loading model...\u001b[39m\n",
      "[2025-06-14 13:01:55,218] [INFO] [accelerate.utils.modeling.get_balanced_memory:990] [PID:67056] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:47<00:00, 15.72s/it]\n",
      "[2025-06-14 13:02:42,426] [INFO] [axolotl.utils.models.load_model:1309] [PID:67056] [RANK:0] cuda memory usage after model load: 6.994GB (+0.305GB cache, +0.884GB misc)\u001b[39m\n",
      "[2025-06-14 13:02:42,447] [INFO] [axolotl.utils.models.prepare_model:1212] [PID:67056] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
      "[2025-06-14 13:02:42,449] [INFO] [axolotl.utils.models.load_model:1348] [PID:67056] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-06-14 13:02:42,451] [INFO] [axolotl.utils.models.load_lora:1542] [PID:67056] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
      "trainable params: 346,079,232 || all params: 7,587,860,480 || trainable%: 4.5610\n",
      "[2025-06-14 13:02:43,171] [INFO] [axolotl.utils.models.load_model:1409] [PID:67056] [RANK:0] cuda memory usage after adapters: 7.799GB (+0.629GB cache, +0.948GB misc)\u001b[39m\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "[2025-06-14 13:02:44,275] [INFO] [httpx._send_single_request:1025] [PID:67056] HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "[2025-06-14 13:02:44,287] [INFO] [httpx._send_single_request:1025] [PID:67056] HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "[2025-06-14 13:02:44,287] [INFO] [httpx._send_single_request:1025] [PID:67056] HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "[2025-06-14 13:02:44,546] [INFO] [httpx._send_single_request:1025] [PID:67056] HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "[2025-06-14 13:02:44,565] [INFO] [httpx._send_single_request:1025] [PID:67056] HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64 \"HTTP/1.1 200 OK\"\n",
      "* Running on public URL: https://ad85c13aac0f994a92.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 8192}. If this is not desired, please set these values explicitly.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "!axolotl inference openchat_lora.yaml --base-model \"/system/environment/output/merged\" --gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317dc268-ddec-4a2d-9e1b-533364c3a850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
